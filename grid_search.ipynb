{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "\n",
    "def extensive_grid_search(df, target_cols):\n",
    "    \"\"\"\n",
    "    Perform extensive grid search for both feature selection and classification.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe\n",
    "    target_cols : list\n",
    "        List of target columns to exclude from features\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    le = LabelEncoder()\n",
    "    df_encoded = df.copy()\n",
    "    for column in df_encoded.select_dtypes(include=['object']).columns:\n",
    "        df_encoded[column] = le.fit_transform(df_encoded[column].astype(str))\n",
    "\n",
    "    X = df_encoded.drop(columns=target_cols, errors='ignore')\n",
    "    y = df_encoded['target'].astype(int)\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = ImbPipeline([\n",
    "        ('sampling', SMOTE(random_state=42)),\n",
    "        ('feature_selection', SelectFromModel(GradientBoostingClassifier())),\n",
    "        ('classifier', GradientBoostingClassifier())\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        # Feature Selection parameters\n",
    "        'feature_selection__threshold': ['mean', '0.5*mean', '1.5*mean'],\n",
    "        'feature_selection__max_features': [5, 7, 9, 11, 13],\n",
    "        'feature_selection__estimator__n_estimators': [50, 100],\n",
    "        \n",
    "        # Classifier parameters\n",
    "        'classifier__n_estimators': [100, 150, 200],\n",
    "        'classifier__learning_rate': [0.05, 0.1, 0.15],\n",
    "        'classifier__max_depth': [3, 4, 5, 6],\n",
    "        'classifier__min_samples_split': [5, 8, 10],\n",
    "        'classifier__min_samples_leaf': [2, 3, 4],\n",
    "        'classifier__subsample': [0.8, 0.9, 1.0],\n",
    "        'classifier__max_features': ['sqrt', 'log2', None]\n",
    "    }\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        'roc_auc': 'roc_auc',\n",
    "        'f1': 'f1',\n",
    "        'accuracy': 'accuracy'\n",
    "    }\n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        scoring=scoring,\n",
    "        refit='roc_auc',\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Fit GridSearchCV\n",
    "    print(\"Starting Grid Search...\")\n",
    "    start_time = time()\n",
    "    grid_search.fit(X, y)\n",
    "    print(f\"Grid Search completed in {(time() - start_time)/60:.2f} minutes\")\n",
    "\n",
    "    # Get results into DataFrame\n",
    "    results = pd.DataFrame(grid_search.cv_results_)\n",
    "    \n",
    "    # Get best parameters and scores\n",
    "    print(\"\\nBest parameters found:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(\"\\nBest scores:\")\n",
    "    print(f\"ROC AUC: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Analyze results\n",
    "    analyze_grid_search_results(results)\n",
    "    \n",
    "    return grid_search, results\n",
    "\n",
    "def analyze_grid_search_results(results):\n",
    "    \"\"\"\n",
    "    Analyze and visualize grid search results.\n",
    "    \"\"\"\n",
    "    # Create figure for multiple plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "    \n",
    "    # 1. Parameter importance plot\n",
    "    param_scores = []\n",
    "    for param in results.params.iloc[0].keys():\n",
    "        scores = []\n",
    "        values = results[f'param_{param}'].unique()\n",
    "        for value in values:\n",
    "            mean_score = results[\n",
    "                results[f'param_{param}'] == value\n",
    "            ]['mean_test_roc_auc'].mean()\n",
    "            scores.append({'param': param, 'value': str(value), 'score': mean_score})\n",
    "        param_scores.extend(scores)\n",
    "    \n",
    "    param_importance_df = pd.DataFrame(param_scores)\n",
    "    \n",
    "    # Plot parameter importance\n",
    "    sns.boxplot(\n",
    "        data=param_importance_df,\n",
    "        x='param',\n",
    "        y='score',\n",
    "        ax=axes[0,0]\n",
    "    )\n",
    "    axes[0,0].set_title('Parameter Importance')\n",
    "    axes[0,0].set_xticklabels(axes[0,0].get_xticklabels(), rotation=45)\n",
    "    \n",
    "    # 2. Score distributions\n",
    "    scores_df = results[['mean_test_roc_auc', 'mean_test_f1', 'mean_test_accuracy']]\n",
    "    scores_df.boxplot(ax=axes[0,1])\n",
    "    axes[0,1].set_title('Score Distributions')\n",
    "    \n",
    "    # 3. Top 10 combinations\n",
    "    top_10_idx = results['mean_test_roc_auc'].nlargest(10).index\n",
    "    top_10_scores = results.iloc[top_10_idx][\n",
    "        ['mean_test_roc_auc', 'mean_test_f1', 'mean_test_accuracy']\n",
    "    ]\n",
    "    top_10_scores.plot(kind='bar', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Top 10 Combinations')\n",
    "    axes[1,0].set_xticklabels(range(1, 11))\n",
    "    \n",
    "    # 4. Learning curves for best model\n",
    "    best_idx = results['mean_test_roc_auc'].idxmax()\n",
    "    train_scores = results.iloc[best_idx][\n",
    "        [col for col in results.columns if 'split' in col and 'train' in col]\n",
    "    ]\n",
    "    test_scores = results.iloc[best_idx][\n",
    "        [col for col in results.columns if 'split' in col and 'test' in col]\n",
    "    ]\n",
    "    \n",
    "    axes[1,1].plot(train_scores, label='Train')\n",
    "    axes[1,1].plot(test_scores, label='Test')\n",
    "    axes[1,1].set_title('Learning Curves (Best Model)')\n",
    "    axes[1,1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed analysis\n",
    "    print(\"\\nTop 5 Parameter Combinations:\")\n",
    "    top_5_idx = results['mean_test_roc_auc'].nlargest(5).index\n",
    "    for idx in top_5_idx:\n",
    "        print(\"\\nParameters:\")\n",
    "        for param, value in results.params.iloc[idx].items():\n",
    "            print(f\"{param}: {value}\")\n",
    "        print(f\"ROC AUC: {results.iloc[idx]['mean_test_roc_auc']:.4f}\")\n",
    "        print(f\"F1 Score: {results.iloc[idx]['mean_test_f1']:.4f}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "def train_best_model(grid_search, X, y):\n",
    "    \"\"\"\n",
    "    Train model with best parameters found.\n",
    "    \"\"\"\n",
    "    # Get best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    # Create pipeline with best parameters\n",
    "    best_pipeline = ImbPipeline([\n",
    "        ('sampling', SMOTE(random_state=42)),\n",
    "        ('feature_selection', SelectFromModel(\n",
    "            GradientBoostingClassifier(**{k.replace('feature_selection__estimator__', ''): v \n",
    "                                        for k, v in best_params.items() \n",
    "                                        if 'feature_selection__estimator__' in k}),\n",
    "            **{k.replace('feature_selection__', ''): v \n",
    "               for k, v in best_params.items() \n",
    "               if 'feature_selection__' in k and 'estimator__' not in k}\n",
    "        )),\n",
    "        ('classifier', GradientBoostingClassifier(**{k.replace('classifier__', ''): v \n",
    "                                                   for k, v in best_params.items() \n",
    "                                                   if 'classifier__' in k}))\n",
    "    ])\n",
    "    \n",
    "    # Fit pipeline\n",
    "    best_pipeline.fit(X, y)\n",
    "    \n",
    "    return best_pipeline\n",
    "\n",
    "# Execute grid search\n",
    "target_columns = [\"target\", \"T_score_fn\", \"T_score_tf\", \"T_score_sp\",\n",
    "                 \"DXXSPN_DXXOSBMD\", \"DXXFEM_DXXNKBMD\", \"DXXFEM_DXXOFBMD\"]\n",
    "\n",
    "print(\"Starting grid search process...\")\n",
    "grid_search, results = extensive_grid_search(df_final, target_columns)\n",
    "\n",
    "# Train best model\n",
    "X = df_final.drop(columns=target_columns, errors='ignore')\n",
    "y = df_final['target'].astype(int)\n",
    "best_model = train_best_model(grid_search, X, y)\n",
    "\n",
    "print(\"\\nBest model has been trained and is ready for use!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
